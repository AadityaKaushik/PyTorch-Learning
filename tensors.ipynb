{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c854278",
   "metadata": {},
   "source": [
    "# Creating a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390e3de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f68125a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce MX250\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd1ba4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce MX250\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU detected by PyTorch.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd6b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.empty(2, 5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66f87b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dd458ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbd757f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3055, 0.0270, 0.0884],\n",
      "        [0.8319, 0.1860, 0.4307]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1df4381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0903, 0.9583, 0.1554],\n",
      "        [0.0384, 0.1026, 0.7071]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de1b6220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9276, 0.5817, 0.0962],\n",
      "        [0.0014, 0.5745, 0.7127]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(234)\n",
    "a = torch.rand(2, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4618c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9276, 0.5817, 0.0962],\n",
      "        [0.0014, 0.5745, 0.7127]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(234)\n",
    "a = torch.rand(2, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "822a06de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,  24,   4],\n",
       "        [ 23,   2, 132],\n",
       "        [ 13,  13,  21]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1, 24, 4], [23, 2, 132], [13, 13, 21]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "812bcf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  6, 10])\n",
      "tensor([ 2.0000,  5.3333,  8.6667, 12.0000])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "tensor([[4, 4, 4, 4, 4, 4, 4],\n",
      "        [4, 4, 4, 4, 4, 4, 4],\n",
      "        [4, 4, 4, 4, 4, 4, 4]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(2, 12, 4) # Print an arithmetic progression\n",
    "print(a)\n",
    "\n",
    "b = torch.linspace(2, 12, 4) # Print evenly spaced values\n",
    "print(b)\n",
    "\n",
    "c = torch.eye(4)\n",
    "print(c)\n",
    "\n",
    "d = torch.full((3, 7), 4)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "409d79e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15a4c1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6522642236672,             0,             0,             0,\n",
      "                     0,             0,             0],\n",
      "        [            0,             0,             0,             0,\n",
      "                     0,             0,             0],\n",
      "        [            0,             0,             0,             0,\n",
      "                     0,             0,             0]])\n"
     ]
    }
   ],
   "source": [
    "e = torch.empty_like(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bec95136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "f = torch.zeros_like(d)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434cfd9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"check_uniform_bounds\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m f = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(f)\n",
      "\u001b[31mRuntimeError\u001b[39m: \"check_uniform_bounds\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "f = torch.rand_like(d)  # Breaks because of datatype issue\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec62647",
   "metadata": {},
   "source": [
    "# Tensor datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "756f1867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "299174e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 4.],\n",
       "        [3., 4., 5.],\n",
       "        [3., 5., 2.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning while creating\n",
    "torch.tensor([[2, 3, 4], [3, 4, 5], [3, 5, 2]], dtype = float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c2ee5c",
   "metadata": {},
   "source": [
    "| **Data Type**             | **Dtype**         | **Description**                                                                                                                                                                |\n",
    "|---------------------------|-------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **32-bit Floating Point** | `torch.float32`   | Standard floating-point type used for most deep learning tasks. Provides a balance between precision and memory usage.                                                         |\n",
    "| **64-bit Floating Point** | `torch.float64`   | Double-precision floating point. Useful for high-precision numerical tasks but uses more memory.                                                                               |\n",
    "| **16-bit Floating Point** | `torch.float16`   | Half-precision floating point. Commonly used in mixed-precision training to reduce memory and computational overhead on modern GPUs.                                            |\n",
    "| **BFloat16**              | `torch.bfloat16`  | Brain floating-point format with reduced precision compared to `float16`. Used in mixed-precision training, especially on TPUs.                                                |\n",
    "| **8-bit Floating Point**  | `torch.float8`    | Ultra-low-precision floating point. Used for experimental applications and extreme memory-constrained environments (less common).                                               |\n",
    "| **8-bit Integer**         | `torch.int8`      | 8-bit signed integer. Used for quantized models to save memory and computation in inference.                                                                                   |\n",
    "| **16-bit Integer**        | `torch.int16`     | 16-bit signed integer. Useful for special numerical tasks requiring intermediate precision.                                                                                    |\n",
    "| **32-bit Integer**        | `torch.int32`     | Standard signed integer type. Commonly used for indexing and general-purpose numerical tasks.                                                                                  |\n",
    "| **64-bit Integer**        | `torch.int64`     | Long integer type. Often used for large indexing arrays or for tasks involving large numbers.                                                                                  |\n",
    "| **8-bit Unsigned Integer**| `torch.uint8`     | 8-bit unsigned integer. Commonly used for image data (e.g., pixel values between 0 and 255).                                                                                    |\n",
    "| **Boolean**               | `torch.bool`      | Boolean type, stores `True` or `False` values. Often used for masks in logical operations.                                                                                      |\n",
    "| **Complex 64**            | `torch.complex64` | Complex number type with 32-bit real and 32-bit imaginary parts. Used for scientific and signal processing tasks.                                                               |\n",
    "| **Complex 128**           | `torch.complex128`| Complex number type with 64-bit real and 64-bit imaginary parts. Offers higher precision but uses more memory.                                                                 |\n",
    "| **Quantized Integer**     | `torch.qint8`     | Quantized signed 8-bit integer. Used in quantized models for efficient inference.                                                                                              |\n",
    "| **Quantized Unsigned Integer** | `torch.quint8` | Quantized unsigned 8-bit integer. Often used for quantized tensors in image-related tasks.                                                                                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce77b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the datatype\n",
    "f.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de3459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
